This ReadMe explains the approach taken towards completing the Course Project for the Getting Clean Data Coursera course. Notes on the data in the columns can be found in Codebook.Rmd(https://github.com/AdityaSridhar/UCI-HAR-Dataset/blob/master/Codebook.Rmd). 

run_analysis.R is the script that contains the code that analyses the UCI HAR Samsung Data and outputs a tidy data set as per Requirement 5 of the Course project. 

The following conditions are assumed as pre-requisites for the script to run successfully:
------------------------------------------------------------------------------------------

1. The current workspace is set inside the UCI-HAR-Dataset folder. E.g. D:/SamsungData/UCI-HAR-Dataset 
2. The dplyr package has been installed. This can be done using the install.packages("dplyr")
3. The reshape2 package has been installed. This can be done using the install.packages("reshape2")

The Script routine consists of:
-------------------------------

1. The training and test data sets are loaded from the files. 
2. The features data which consists of the various kinds of measurements is loaded.
3. The names of the columns of the xtest and xtrain datasets is mapped to the features data.
4. The activity labels which consists of the kind of activities performed in the experiment is loaded.
5. The levels of the activity labels is specified in the correct order and with descriptive labels.
6. The ytest and ytrain data is coerced as a factor. The levels of these factors are mapped to the activity labels factor. 
7. The names of the ytest and ytrain are appropriately named as "Activity"
8, The xtest and ytest data is combined to form one dataframe. Similar action is performed on the training dataset.
9. The Subject data for both the training and test datasets is loaded and combined with the respective data frames.
10. The training and test datasets are merged using the rbind command.
11. The unwanted columns are removed by searching for only the column names containing the mean or std string.
12. The column names are rationalized using the make.names function to make them compatible with R.
13. The tidy data set with the averages calculated for the measurements is generated. 
14. The tidy data is melted to form a long data set with the Subject and Activity as ID Vars.

Justification that the data is tidy:
------------------------------------
As per Hadley Wickham's paper on Tidy data, the criteria for defining a tidy data set are:
In tidy data:
1. Each variable forms a column.
2. Each observation forms a row.
3. Each type of observational unit forms a table.

A variable according to the same paper is supposed to contain values of an underlying attribute. In the tidy data set generated by the submitted script, the Subject, Activity columns clearly are variables with values. The third column named "variable" is a column consisting of all the measured variables. The fourth column represents the variable containing the average values of the measured variable for each subject and activity. This satisfies Rule 1. Each observation is the average value of the measured variable for a given subject and activity, and it forms a row of its own satisfying Rule 2 and 3. The requirement 5 in the course project asks for a data set that provides the average value for each variable for each subject and activity. Therefore, the long data set format was chosen to represent each kind of measurement under a single column. 

The MeanFreq() data was also included because all the mean and std data was asked to be considered for this problem. Without knowing the actual use of the resulting data set, it cannot be clearly discerned whether the meanfreqs() should be discared. Therefore they have been retained. 

References: Hadley Wickham's paper on Tidy Data : http://www.jstatsoft.org/v59/i10/paper